{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Advanced Lane Lines and Vehicle Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Imports, Tools, Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "# from sklearn.model_selection import train_test_split # >= 0.18 TODO\n",
    "from sklearn.cross_validation import train_test_split # 0.17\n",
    "from sklearn import grid_search\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "# Configuration\n",
    "SRC_TF = np.float32([ [262.0, 680.0], [1042.0, 680.0], [701.0, 460.0], [580.0, 460.0] ])\n",
    "DST_TF = np.float32([ [262.0, 720.0], [1042.0, 720.0], [1042.0, 0.0], [262.0, 0.0] ])\n",
    "\n",
    "# Choose the number of sliding windows\n",
    "nwindows = 9\n",
    "# Set the width of the windows +/- margin\n",
    "margin = 100\n",
    "# Set minimum number of pixels found to recenter window\n",
    "minpix = 50\n",
    "\n",
    "HISTORY_SIZE = 50\n",
    "\n",
    "ksize=5\n",
    "\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "\n",
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False\n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None\n",
    "        self.best_fit_amnt = 0\n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = []\n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None\n",
    "        # avg number of points in a fit\n",
    "        self.average_fit_points = 0.0\n",
    "        # amount of fit points\n",
    "        self.amnt_fit_points = []\n",
    "    \n",
    "    def addToAverageFitPoints(self, fit_points):\n",
    "        self.amnt_fit_points.append(float(len(fit_points)))\n",
    "        \n",
    "        if len(self.amnt_fit_points) > HISTORY_SIZE:\n",
    "            del self.amnt_fit_points[0]\n",
    "            \n",
    "        self.average_fit_points = sum(self.amnt_fit_points) / float(len(self.amnt_fit_points))\n",
    "    \n",
    "    def addToAverageBestFit(self, fit, img_shape):\n",
    "        self.averageOverCurrentFit(fit, img_shape)\n",
    "        #self.averageOverXFitted(fit, img_shape)\n",
    "    \n",
    "    def averageOverCurrentFit(self, fit, img_shape):\n",
    "        self.current_fit.append(fit)\n",
    "        if len(self.current_fit) > HISTORY_SIZE:\n",
    "            del self.current_fit[0]\n",
    "        sum_fit = np.zeros_like(fit)\n",
    "        for prev_fit in self.current_fit:\n",
    "            sum_fit += prev_fit\n",
    "        \n",
    "        self.best_fit = sum_fit / len(self.current_fit)\n",
    "    \n",
    "    def averageOverXFitted(self, fit, img_shape):\n",
    "        \n",
    "        if len(self.recent_xfitted) > HISTORY_SIZE:\n",
    "            del self.recent_xfitted[0]\n",
    "        \n",
    "        # Generate x and y values for plotting\n",
    "        ploty = np.linspace(0, img_shape[0]-1, img_shape[0] )\n",
    "        plotx = fit[0]*ploty**2 + fit[1]*ploty + fit[2]\n",
    "        \n",
    "        self.recent_xfitted.append(plotx)\n",
    "        \n",
    "        complete_y = []\n",
    "        complete_x = []\n",
    "        for prev_xfitted in self.recent_xfitted:\n",
    "            complete_y.extend(ploty)\n",
    "            complete_x.extend(prev_xfitted)\n",
    "            \n",
    "        self.best_fit = np.polyfit(complete_y, complete_x, 2)\n",
    "        \n",
    "        \n",
    "    def toStrings(self):\n",
    "        return [\"Best fit: \" + str(self.best_fit), \n",
    "                \"Detected? \" + str(self.detected), \n",
    "                \"CurFit length: \" + str(len(self.current_fit)),\n",
    "                \"Xfitted length: \" + str(len(self.recent_xfitted)),\n",
    "                \"Avg Fit Points: \" + str(self.average_fit_points)]\n",
    "        \n",
    "        \n",
    "class ImageDisplay():\n",
    "    def __init__(self, image, label, cmap_str):\n",
    "        self.image = image\n",
    "        self.label = label\n",
    "        self.cmap_str = cmap_str\n",
    "\n",
    "def wAvg(val1, w1, val2, w2):\n",
    "    return (val1 * w1 + val2 * w2) / 2.0\n",
    "\n",
    "def calibrate(nx, ny):\n",
    "    \n",
    "    objpoints = []\n",
    "    imgpoints = []\n",
    "    \n",
    "    images = glob.glob('camera_cal/calibration*.jpg')\n",
    "    for idx, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        objp = np.zeros((nx*ny, 3), np.float32)\n",
    "        objp[:, :2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2) # x, y coordinates\n",
    "\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "\n",
    "        if ret == True: # meaning that we found chessboard corners\n",
    "            imgpoints.append(corners)\n",
    "            objpoints.append(objp)\n",
    "            img = cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "            cv2.imshow('img', img)\n",
    "            cv2.waitKey(500)\n",
    "            \n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "    \n",
    "    return ret, mtx, dist, rvecs, tvecs\n",
    "\n",
    "def thresh(gray, thresh=(0, 255)):\n",
    "    binary_output = np.zeros_like(gray)\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    binary_output[(gray >= thresh[0]) & (gray <= thresh[1])] = 1\n",
    "\n",
    "    # Return the result\n",
    "    return binary_output\n",
    "\n",
    "def abs_sobel_thresh(gray, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Apply x or y gradient with the OpenCV Sobel() function\n",
    "    # and take the absolute value\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1))\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Create a copy and apply the threshold\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "\n",
    "    # Return the result\n",
    "    return binary_output\n",
    "\n",
    "def mag_thresh(gray, sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    if thresh is not None:\n",
    "        binary_output = np.zeros_like(gradmag)\n",
    "        binary_output[(gradmag >= thresh[0]) & (gradmag <= thresh[1])] = 1\n",
    "        # Return the binary image\n",
    "        return binary_output\n",
    "    \n",
    "    return gradmag\n",
    "\n",
    "def dir_threshold(gray, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_output =  np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output\n",
    "\n",
    "def perspective_transform(img):\n",
    "    M = cv2.getPerspectiveTransform(SRC_TF, DST_TF)\n",
    "    warped = cv2.warpPerspective(img, M, (img.shape[1], img.shape[0]))\n",
    "    return warped\n",
    "\n",
    "def inverse_perspective_transform(img):\n",
    "    Minv = cv2.getPerspectiveTransform(DST_TF, SRC_TF)\n",
    "    warped = cv2.warpPerspective(img, Minv, (img.shape[1], img.shape[0]))\n",
    "    return warped\n",
    "\n",
    "def gray(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    return gray\n",
    "\n",
    "def HLS(img):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    return hls\n",
    "\n",
    "def YUV(img):\n",
    "    yuv = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "    return yuv\n",
    "\n",
    "def H(img):\n",
    "    hls = HLS(img)\n",
    "    return hls[:,:,0]\n",
    "\n",
    "def L(img):\n",
    "    hls = HLS(img)\n",
    "    return hls[:,:,1]\n",
    "\n",
    "def S(img):\n",
    "    hls = HLS(img)\n",
    "    return hls[:,:,2]\n",
    "\n",
    "def Y(img):\n",
    "    yuv = YUV(img)\n",
    "    return yuv[:,:,0]\n",
    "\n",
    "def U(img):\n",
    "    yuv = YUV(img)\n",
    "    return yuv[:,:,1]\n",
    "\n",
    "def V(img):\n",
    "    yuv = YUV(img)\n",
    "    return yuv[:,:,2]\n",
    "\n",
    "def get_histogram(binary_warped, ratio=2.0):\n",
    "    histogram = np.sum(binary_warped[int(binary_warped.shape[0]/2.0):,:], axis=0)\n",
    "    return histogram\n",
    "\n",
    "def sliding_window(binary_warped, histogram=None):\n",
    "    \n",
    "    # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    if histogram is None:\n",
    "        histogram = get_histogram(binary_warped)\n",
    "    \n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    \n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "    \n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    \n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    \n",
    "    out_img = draw_polygon_with_margin_around_polynomial(out_img, left_fit, 20)\n",
    "    out_img = draw_polygon_with_margin_around_polynomial(out_img, right_fit, 20)\n",
    "    \n",
    "    texts = []\n",
    "    #texts.extend(left_line.toStrings())\n",
    "    #texts.extend(right_line.toStrings())\n",
    "    #texts.append(\"Current Fit Points: L \" + str(len(left_lane_inds)) + \",   R \" + str(len(right_lane_inds)))\n",
    "    \n",
    "    out_img = addText(out_img, texts)\n",
    "    \n",
    "    return out_img, left_fit, right_fit\n",
    "\n",
    "def draw_polygon_with_margin_around_polynomial(out_img, polynomial, margin, color=(0, 255, 0)):\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, out_img.shape[0]-1, out_img.shape[0] )\n",
    "    plotx = polynomial[0]*ploty**2 + polynomial[1]*ploty + polynomial[2]\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    poly_window1 = np.array([np.transpose(np.vstack([plotx-margin, ploty]))])\n",
    "    poly_window2 = np.array([np.flipud(np.transpose(np.vstack([plotx+margin, ploty])))])\n",
    "    poly_pts = np.hstack((poly_window1, poly_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([poly_pts]), color)\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def draw_polygon_between_polynomials(out_img, left_fit, right_fit):\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    \n",
    "    ploty = np.linspace(0, out_img.shape[0]-1, out_img.shape[0] )\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    cv2.fillPoly(window_img, np.int_([pts]), (0, 255, 0))\n",
    "    \n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def draw_lane_undistorted(undistd, left_fit, right_fit):\n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    #lane_zeros = np.zeros_like(undistd).astype(np.uint8)\n",
    "    #lane_color = np.dstack((lane_zeros, lane_zeros, lane_zeros))\n",
    "    lane_color = np.zeros_like(undistd)\n",
    "    \n",
    "    # draw the lane in top-down view, on the blank image\n",
    "    lane_color = draw_polygon_between_polynomials(lane_color, left_fit, right_fit)\n",
    "    \n",
    "    # warp the lane back into the viewpoint of the car camera\n",
    "    lane_color_warped = inverse_perspective_transform(lane_color)\n",
    "    \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undistd, 1, lane_color_warped, 0.3, 0)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def detect_from_previous(binary_warped, left_fit, right_fit):\n",
    "    \n",
    "    # Assume you now have a new warped binary image \n",
    "    # from the next frame of video (also called \"binary_warped\")\n",
    "    # It's now much easier to find line pixels!\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    \n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    result = draw_polygon_with_margin_around_polynomial(out_img, left_fit, margin)\n",
    "    result = draw_polygon_with_margin_around_polynomial(result, right_fit, margin)\n",
    "    #result = draw_polygon_with_margin_around_polynomial(result, left_line.best_fit, margin, color=(0, 0, 255))\n",
    "    #result = draw_polygon_with_margin_around_polynomial(result, right_line.best_fit, margin, color=(0, 0, 255))\n",
    "    \n",
    "    texts = []\n",
    "    #texts.append(\"Current Fit Points: L \" + str(len(left_lane_inds)) + \",   R \" + str(len(right_lane_inds)))\n",
    "    \n",
    "    out_img = addText(out_img, texts)\n",
    "    \n",
    "    #result = draw_polygon_between_polynomials(result, left_fit, right_fit)\n",
    "    \n",
    "    return result, left_fit, right_fit\n",
    "\n",
    "def lane_offset(left_fit, right_fit, img):\n",
    "    lowestX_left = getLowestXPos(left_fit, lane_img)\n",
    "    lowestX_right = getLowestXPos(right_fit, lane_img)\n",
    "    avg = (lowestX_left + lowestX_right) / 2.0\n",
    "    center = img.shape[1]/2.0\n",
    "    offset = avg - center\n",
    "    return xToM(offset)\n",
    "\n",
    "def xToM(x):\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    return x * xm_per_pix\n",
    "\n",
    "def getLowestXPos(fit, img):\n",
    "    \n",
    "    # Fit new polynomials to x,y in world space\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0] )\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    fitx = fit[0]*ploty**2 + fit[1]*ploty + fit[2]\n",
    "    \n",
    "    return fitx[0]\n",
    "\n",
    "def measure_curvature(fit, img):\n",
    "    \n",
    "    # measure curvature in pixel space\n",
    "    y_eval = np.max(img.shape[0])\n",
    "    px_curverad = ((1 + (2*fit[0]*y_eval + fit[1])**2)**1.5) / np.absolute(2*fit[0])\n",
    "\n",
    "    # measure curvature in real world\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0] )\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    fitx = fit[0]*ploty**2 + fit[1]*ploty + fit[2]\n",
    "    \n",
    "    fit_cr = np.polyfit(ploty*ym_per_pix, fitx*xm_per_pix, 2)\n",
    "\n",
    "    # Calculate the new radii of curvature\n",
    "    world_curverad = ((1 + (2*fit_cr[0]*y_eval*ym_per_pix + fit_cr[1])**2)**1.5) / np.absolute(2*fit_cr[0])\n",
    "\n",
    "    return px_curverad, world_curverad\n",
    "\n",
    "def undist(image):\n",
    "    return cv2.undistort(image, mtx, dist, None, mtx)\n",
    "        \n",
    "def process_image_find_cspace(image):\n",
    "    undistd = undist(image)\n",
    "    persp = perspective_transform(undistd)\n",
    "    return concatenate_4_images(undistd, H(undistd), L(undistd), S(undistd))\n",
    "\n",
    "def process_image_video1(image):\n",
    "    undistd = undist(image)\n",
    "    persp = perspective_transform(undistd)\n",
    "    gradx = abs_sobel_thresh(L(persp), orient='x', sobel_kernel=ksize, thresh=(10, 100))\n",
    "    \n",
    "    global left_line, right_line\n",
    "    \n",
    "    if (left_line.detected and right_line.detected):\n",
    "        result, left_fit, right_fit = detect_from_previous(gradx, left_line.best_fit, right_line.best_fit)\n",
    "        \n",
    "        # average best fit\n",
    "        left_line.addToAverageBestFit(left_fit, result.shape)\n",
    "        right_line.addToAverageBestFit(right_fit, result.shape)\n",
    "\n",
    "    else:\n",
    "        result, left_fit, right_fit = sliding_window(gradx)\n",
    "        \n",
    "        left_line.detected = True\n",
    "        right_line.detected = True\n",
    "        \n",
    "        # average best fit\n",
    "        left_line.addToAverageBestFit(left_fit, result.shape)\n",
    "        right_line.addToAverageBestFit(right_fit, result.shape)\n",
    "    \n",
    "    result_warped = draw_lane_undistorted(undistd, left_line.best_fit, right_line.best_fit)\n",
    "    \n",
    "    texts = []\n",
    "    \n",
    "    if left_line.detected:\n",
    "        left_px_curverad, left_world_curverad = measure_curvature(left_line.best_fit, gradx)\n",
    "        left_line.radius_of_curvature = left_world_curverad\n",
    "        texts.append(\"Left World Curverad: \" + str(left_world_curverad))\n",
    "    \n",
    "    if right_line.detected:\n",
    "        right_px_curverad, right_world_curverad = measure_curvature(right_line.best_fit, gradx)\n",
    "        right_line.radius_of_curvature = right_world_curverad\n",
    "        texts.append(\"Right World Curverad: \" + str(right_world_curverad))\n",
    "    \n",
    "    if left_line.detected and right_line.detected:\n",
    "        offset = lane_offset(left_line.best_fit, right_line.best_fit, gradx)\n",
    "        texts.append(\"Lane Offset: \" + str(offset))\n",
    "    \n",
    "    result_warped = addText(result_warped, texts)\n",
    "    \n",
    "    #return concatenate_4_images(image, gradx, result, result_warped)\n",
    "    return result_warped\n",
    "\n",
    "def process_image_video2(image):\n",
    "    try:\n",
    "        undistd = undist(image)\n",
    "        persp = perspective_transform(undistd)\n",
    "        gradx = abs_sobel_thresh(L(persp), orient='x', sobel_kernel=ksize, thresh=(30, 100))\n",
    "\n",
    "        left_lane_line = np.zeros_like(gradx)\n",
    "        thresholded_L = thresh(L(persp), thresh=(130, 255))\n",
    "        thresholded_S = thresh(S(persp), thresh=(15, 255))\n",
    "        left_lane_line[(thresholded_L == 1) & (thresholded_S == 1)] = 1\n",
    "\n",
    "        right_lane_line = thresh(L(persp), thresh=(180, 255))\n",
    "        right_lane_line_strict = np.zeros_like(gradx)\n",
    "        right_lane_line_strict[(right_lane_line == 1) & (gradx == 1)] = 1\n",
    "\n",
    "        both_lane_lines = np.zeros_like(gradx)\n",
    "        both_lane_lines[(left_lane_line == 1) | (right_lane_line_strict == 1)] = 1\n",
    "\n",
    "        global left_line, right_line\n",
    "        \n",
    "        if (left_line.detected and right_line.detected):\n",
    "            result, left_fit, right_fit = detect_from_previous(both_lane_lines, left_line.best_fit, right_line.best_fit)\n",
    "\n",
    "            # average best fit\n",
    "            left_line.addToAverageBestFit(left_fit, result.shape)\n",
    "            right_line.addToAverageBestFit(right_fit, result.shape)\n",
    "\n",
    "        else:\n",
    "            histogram = get_histogram(both_lane_lines, ratio=1.4)\n",
    "            result, left_fit, right_fit = sliding_window(both_lane_lines, histogram)\n",
    "\n",
    "            left_line.detected = True\n",
    "            right_line.detected = True\n",
    "\n",
    "            # average best fit\n",
    "            left_line.addToAverageBestFit(left_fit, result.shape)\n",
    "            right_line.addToAverageBestFit(right_fit, result.shape)\n",
    "        \n",
    "        result_warped = draw_lane_undistorted(undistd, left_line.best_fit, right_line.best_fit)\n",
    "    \n",
    "        texts = []\n",
    "\n",
    "        if left_line.detected:\n",
    "            left_px_curverad, left_world_curverad = measure_curvature(left_line.best_fit, gradx)\n",
    "            left_line.radius_of_curvature = left_world_curverad\n",
    "            texts.append(\"Left World Curverad: \" + str(left_world_curverad))\n",
    "            texts.append(\"Left Px Curverad: \" + str(left_px_curverad))\n",
    "\n",
    "        if right_line.detected:\n",
    "            right_px_curverad, right_world_curverad = measure_curvature(right_line.best_fit, gradx)\n",
    "            right_line.radius_of_curvature = right_world_curverad\n",
    "            texts.append(\"Right World Curverad: \" + str(right_world_curverad))\n",
    "            texts.append(\"Right Px Curverad: \" + str(right_px_curverad))\n",
    "            \n",
    "        if left_line.detected and right_line.detected:\n",
    "            offset = lane_offset(left_line.best_fit, right_line.best_fit, gradx)\n",
    "            texts.append(\"Lane Offset: \" + str(offset))\n",
    "\n",
    "        result_warped = addText(result_warped, texts)\n",
    "        ''\n",
    "        #return concatenate_4_images(left_lane_line, right_lane_line, result, result_warped)\n",
    "        return result_warped\n",
    "    except:\n",
    "        #return concatenate_4_images(left_lane_line, right_lane_line, both_lane_lines, both_lane_lines)\n",
    "        #return both_lane_lines\n",
    "        return undistd\n",
    "    \n",
    "def process_image(image):\n",
    "\n",
    "    #image_o = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    #cv2.imwrite(\"test_images/test_challenge_4.jpg\", image_o)\n",
    "    \n",
    "    undistd = undist(image)\n",
    "    persp = perspective_transform(undistd)\n",
    "    #gradx = abs_sobel_thresh(Y(persp), orient='x', sobel_kernel=ksize, thresh=(50, 200)) # was 10,100\n",
    "\n",
    "    #mag_L = mag_thresh(L(persp), thresh=(50, 200))\n",
    "    #mag_Y = mag_thresh(Y(persp), thresh=None)\n",
    "    #mag_U = mag_thresh(U(persp), thresh=(50, 200))\n",
    "    #mag_S = mag_thresh(S(persp), thresh=(50, 200))\n",
    "    \n",
    "    #left_lane_line = np.zeros_like(gradx)\n",
    "    #thresholded_L = thresh(L(persp), thresh=(130, 255))\n",
    "    thresholded_Y = thresh(Y(persp), thresh=(200, 255))\n",
    "    thresholded_V = thresh(V(persp), thresh=(150, 255))\n",
    "    thresholded_L = thresh(L(persp), thresh=(180, 255))\n",
    "    thresholded_H = thresh(H(persp), thresh=(100, 102))\n",
    "    #left_lane_line[(thresholded_L == 1) & (thresholded_S == 1)] = 1\n",
    "\n",
    "    #right_lane_line = thresh(L(persp), thresh=(180, 255))\n",
    "    #right_lane_line_strict = np.zeros_like(gradx)\n",
    "    #right_lane_line_strict[(right_lane_line == 1) & (gradx == 1)] = 1\n",
    "\n",
    "\n",
    "\n",
    "    #both_lane_lines = np.zeros_like(gradx)\n",
    "    #both_lane_lines[(left_lane_line == 1) | (right_lane_line_strict == 1)] = 1\n",
    "\n",
    "    #global left_line, right_line\n",
    "\n",
    "    #result_sl, left_line, right_line = sliding_window(both_lane_lines, left_line, right_line)\n",
    "    #if (left_line.detected and right_line.detected):\n",
    "    #    result, left_line, right_line = detect_from_previous(both_lane_lines, left_line, right_line)\n",
    "\n",
    "    return concatenate_4_images(thresholded_Y, thresholded_L, thresholded_H, thresholded_V)\n",
    "\n",
    "def addText(image, texts):\n",
    "    y = 100\n",
    "    y_offset = 50\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    for text in texts:\n",
    "        image = cv2.putText(image, text, (50, y), font, 1,(0,0,255),3)\n",
    "        y += y_offset\n",
    "    s\n",
    "    return image\n",
    "\n",
    "def grayToColor(image):\n",
    "    if (len(image.shape) < 3):\n",
    "        return np.dstack((image, image, image))*255\n",
    "    return image\n",
    "\n",
    "def concatenate_4_images(image1, image2, image3, image4):\n",
    "    image1 = grayToColor(image1)\n",
    "    image2 = grayToColor(image2)\n",
    "    image3 = grayToColor(image3)\n",
    "    image4 = grayToColor(image4)\n",
    "    \n",
    "    left = np.concatenate((image1, image3), axis=0)\n",
    "    right = np.concatenate((image2, image4), axis=0)\n",
    "    return np.concatenate((left, right), axis=1)\n",
    "\n",
    "def show_multiple(image_displays):\n",
    "    fontsize = 10\n",
    "    figsize = (20, 10)\n",
    "    cols = 2\n",
    "    \n",
    "    rows = math.ceil(len(image_displays) / cols)\n",
    "    print(\"image canvas with\", cols, \"cols and\", rows, \"rows\")\n",
    "    \n",
    "    f, ( canvas ) = plt.subplots(rows, cols, figsize=figsize)\n",
    "    \n",
    "    for image_display_index in range(len(image_displays)):\n",
    "        image_display = image_displays[image_display_index]\n",
    "        \n",
    "        if rows > 1:\n",
    "            row = math.floor( float(image_display_index) / float(cols))\n",
    "            col = image_display_index % cols\n",
    "            print(image_display.label, \"goes to\", str(row), str(col))\n",
    "            ax = canvas[row][col]\n",
    "        else:\n",
    "            ax = canvas[image_display_index]     \n",
    "        \n",
    "        ax.imshow(image_display.image, cmap=image_display.cmap_str)\n",
    "        ax.set_title(image_display.label, fontsize=fontsize)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Graveyard\n",
    "\n",
    "def find_matches(img, template_list):\n",
    "    # Make a copy of the image to draw on\n",
    "    # Define an empty list to take bbox coords\n",
    "    bbox_list = []\n",
    "    # Iterate through template list\n",
    "    # Read in templates one by one\n",
    "    method = cv2.TM_CCOEFF_NORMED\n",
    "    for tmp_path in template_list:\n",
    "        tmp = mpimg.imread(tmp_path)\n",
    "        result = cv2.matchTemplate(img, tmp, method)\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "        #print(min_val, max_val, min_loc, max_loc)\n",
    "        w, h = (tmp.shape[1], tmp.shape[0])\n",
    "        if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "            top_left = min_loc\n",
    "        else:\n",
    "            top_left = max_loc\n",
    "        bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "        # Append bbox position to list\n",
    "        bbox_list.append((top_left, bottom_right))\n",
    "    return bbox_list\n",
    "\n",
    "def plot_color_hist(rh, gh, bh, bincen, feature_vec):\n",
    "    # Plot a figure with all three bar charts\n",
    "    if rh is not None:\n",
    "        fig = plt.figure(figsize=(12,3))\n",
    "        plt.subplot(131)\n",
    "        plt.bar(bincen, rh[0])\n",
    "        plt.xlim(0, 256)\n",
    "        plt.title('R Histogram')\n",
    "        plt.subplot(132)\n",
    "        plt.bar(bincen, gh[0])\n",
    "        plt.xlim(0, 256)\n",
    "        plt.title('G Histogram')\n",
    "        plt.subplot(133)\n",
    "        plt.bar(bincen, bh[0])\n",
    "        plt.xlim(0, 256)\n",
    "        plt.title('B Histogram')\n",
    "        fig.tight_layout()\n",
    "    else:\n",
    "        print('Your function is returning None for at least one variable...')\n",
    "\n",
    "def draw_sliding_window_boxes(image):\n",
    "    windows = slide_window(image, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(128, 128), xy_overlap=(0.5, 0.5))\n",
    "                       \n",
    "    window_img = draw_boxes(image, windows, color=(0, 0, 255), thick=6)                    \n",
    "    plt.imshow(window_img)\n",
    "\n",
    "def plot3d(pixels, colors_rgb, axis_labels=list(\"RGB\"), axis_limits=[(0, 255), (0, 255), (0, 255)]):\n",
    "    \"\"\"Plot pixels in 3D.\"\"\"\n",
    "\n",
    "    # Create figure and 3D axes\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = Axes3D(fig)\n",
    "\n",
    "    # Set axis limits\n",
    "    ax.set_xlim(*axis_limits[0])\n",
    "    ax.set_ylim(*axis_limits[1])\n",
    "    ax.set_zlim(*axis_limits[2])\n",
    "\n",
    "    # Set axis labels and sizes\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14, pad=8)\n",
    "    ax.set_xlabel(axis_labels[0], fontsize=16, labelpad=16)\n",
    "    ax.set_ylabel(axis_labels[1], fontsize=16, labelpad=16)\n",
    "    ax.set_zlabel(axis_labels[2], fontsize=16, labelpad=16)\n",
    "\n",
    "    # Plot pixel values with colors given in colors_rgb\n",
    "    ax.scatter(\n",
    "        pixels[:, :, 0].ravel(),\n",
    "        pixels[:, :, 1].ravel(),\n",
    "        pixels[:, :, 2].ravel(),\n",
    "        c=colors_rgb.reshape((-1, 3)), edgecolors='none')\n",
    "\n",
    "    return ax  # return Axes3D object for further manipulation\n",
    "\n",
    "def explore_color(img_path): # TODO img as argument\n",
    "    # Read a color image\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    # Select a small fraction of pixels to plot by subsampling it\n",
    "    scale = max(img.shape[0], img.shape[1], 64) / 64  # at most 64 rows and columns\n",
    "    img_small = cv2.resize(img, (np.int(img.shape[1] / scale), np.int(img.shape[0] / scale)), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Convert subsampled image to desired color space(s)\n",
    "    img_small_RGB = cv2.cvtColor(img_small, cv2.COLOR_BGR2RGB)  # OpenCV uses BGR, matplotlib likes RGB\n",
    "    img_small_HSV = cv2.cvtColor(img_small, cv2.COLOR_BGR2HSV)\n",
    "    img_small_HLS = cv2.cvtColor(img_small, cv2.COLOR_BGR2HLS)\n",
    "    img_small_YUV = cv2.cvtColor(img_small, cv2.COLOR_BGR2YUV)\n",
    "    img_small_LUV = cv2.cvtColor(img_small, cv2.COLOR_BGR2LUV)\n",
    "    img_small_rgb = img_small_RGB / 255.  # scaled to [0, 1], only for plotting\n",
    "\n",
    "    # Plot and show\n",
    "    plot3d(img_small_RGB, img_small_rgb)\n",
    "    plt.show()\n",
    "\n",
    "    plot3d(img_small_HSV, img_small_rgb, axis_labels=list(\"HSV\"))\n",
    "    plt.show()\n",
    "    \n",
    "    plot3d(img_small_HLS, img_small_rgb, axis_labels=list(\"HLS\"))\n",
    "    plt.show()\n",
    "    \n",
    "    plot3d(img_small_YUV, img_small_rgb, axis_labels=list(\"YUV\"))\n",
    "    plt.show()\n",
    "    \n",
    "    plot3d(img_small_LUV, img_small_rgb, axis_labels=list(\"LUV\"))\n",
    "    plt.show()\n",
    "\n",
    "def normalize_and_show_features():\n",
    "    images = glob.glob('*.jpeg')\n",
    "    cars = []\n",
    "    notcars = []\n",
    "    for image in images:\n",
    "        if 'image' in image or 'extra' in image:\n",
    "            notcars.append(image)\n",
    "        else:\n",
    "            cars.append(image)\n",
    "\n",
    "    car_features = extract_features(cars, cspace='RGB', spatial_size=(32, 32),\n",
    "                            hist_bins=32, hist_range=(0, 256))\n",
    "    notcar_features = extract_features(notcars, cspace='RGB', spatial_size=(32, 32),\n",
    "                            hist_bins=32, hist_range=(0, 256))\n",
    "\n",
    "    if len(car_features) > 0:\n",
    "        # Create an array stack of feature vectors\n",
    "        X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "        # Fit a per-column scaler\n",
    "        X_scaler = StandardScaler().fit(X)\n",
    "        # Apply the scaler to X\n",
    "        scaled_X = X_scaler.transform(X)\n",
    "        car_ind = np.random.randint(0, len(cars))\n",
    "        # Plot an example of raw and scaled features\n",
    "        fig = plt.figure(figsize=(12,4))\n",
    "        plt.subplot(131)\n",
    "        plt.imshow(mpimg.imread(cars[car_ind]))\n",
    "        plt.title('Original Image')\n",
    "        plt.subplot(132)\n",
    "        \n",
    "def parameter_tuning():\n",
    "    parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "    svr = svm.SVC()\n",
    "    clf = grid_search.GridSearchCV(svr, parameters)\n",
    "    clf.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Singleton(type):\n",
    "    _instances = {}\n",
    "    def __call__(cls, *args, **kwargs):\n",
    "        if cls not in cls._instances:\n",
    "            cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs)\n",
    "        return cls._instances[cls]\n",
    "\n",
    "class Configuration(metaclass=Singleton):\n",
    "    def __init__(self):\n",
    "        self.COLOR_SPACE = \"YCrCb\"\n",
    "        self.SPATIAL_SIZE = (16, 16)\n",
    "        self.HIST_BINS = 16\n",
    "        self.ORIENTATIONS = 9\n",
    "        self.PIX_PER_CELL = 8\n",
    "        self.CELLS_PER_BLOCK = 2\n",
    "        self.HOG_CHANNEL = \"ALL\"\n",
    "        self.SPATIAL_FEAT = True\n",
    "        self.HIST_FEAT = True\n",
    "        self.HOG_FEAT = True\n",
    "        self.SCALE = 1.5\n",
    "        self.HIST_RANGE = (0, 1)\n",
    "        self.Y_START_STOP = [400, 670]\n",
    "        \n",
    "class RuntimeData(metaclass=Singleton):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.heatmap = None\n",
    "\n",
    "def read_image(img_file):\n",
    "    image = mpimg.imread(img_file)\n",
    "    raw_image = np.copy(image)\n",
    "    \n",
    "    if \".jpg\" in img_file or \".JPG\" in img_file:\n",
    "        image = image.astype(np.float32)/255\n",
    "    \n",
    "    return image, raw_image\n",
    "    \n",
    "def convert_color(img, src, tgt):\n",
    "    return convert_from_RGB(img, tgt)\n",
    "\n",
    "def convert_from_RGB(img, tgt):\n",
    "    if tgt != 'RGB':\n",
    "        if tgt == 'HSV':\n",
    "            return cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif tgt == 'LUV':\n",
    "            return cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif tgt == 'HLS':\n",
    "            return cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif tgt == 'YUV':\n",
    "            return cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif tgt == 'YCrCb':\n",
    "            return cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    else: \n",
    "        return np.copy(img)\n",
    "        \n",
    "    return None\n",
    "\n",
    "def add_heat(heatmap, bbox_list, inc):\n",
    "    for box in bbox_list:\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += inc\n",
    "\n",
    "    return heatmap\n",
    "\n",
    "def cooldown(heatmap, dec):\n",
    "    heatmap -= dec\n",
    "    return heatmap\n",
    "    \n",
    "def apply_threshold(heatmap, threshold):\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    return heatmap\n",
    "\n",
    "def clip_heatmap(heatmap, lower, upper):\n",
    "    return np.clip(heatmap, lower, upper)\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img\n",
    "\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, \n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                  transform_sqrt=False, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, \n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), \n",
    "                       transform_sqrt=False, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    color1 = cv2.resize(img[:,:,0], size).ravel()\n",
    "    color2 = cv2.resize(img[:,:,1], size).ravel()\n",
    "    color3 = cv2.resize(img[:,:,2], size).ravel()\n",
    "    return np.hstack((color1, color2, color3))\n",
    "                        \n",
    "def color_hist(img, nbins=32, bins_range=(0, 1)):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "\n",
    "def single_img_features(img):\n",
    "                \n",
    "    color_space = Configuration().COLOR_SPACE\n",
    "    spatial_size = Configuration().SPATIAL_SIZE\n",
    "    hist_bins = Configuration().HIST_BINS\n",
    "    orient = Configuration().ORIENTATIONS\n",
    "    pix_per_cell = Configuration().PIX_PER_CELL\n",
    "    cell_per_block = Configuration().CELLS_PER_BLOCK\n",
    "    hog_channel = Configuration().HOG_CHANNEL\n",
    "    spatial_feat = Configuration().SPATIAL_FEAT\n",
    "    hist_feat = Configuration().HIST_FEAT\n",
    "    hog_feat = Configuration().HOG_FEAT\n",
    "    \n",
    "    #1) Define an empty list to receive features\n",
    "    img_features = []\n",
    "    #2) Apply color conversion if other than 'RGB'\n",
    "    feature_image = convert_color(img, \"RGB\", color_space)\n",
    "    #3) Compute spatial features if flag is set\n",
    "    if spatial_feat == True:\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        #4) Append features to list\n",
    "        img_features.append(spatial_features)\n",
    "    #5) Compute histogram features if flag is set\n",
    "    if hist_feat == True:\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "        #6) Append features to list\n",
    "        img_features.append(hist_features)\n",
    "    #7) Compute HOG features if flag is set\n",
    "    if hog_feat == True:\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.extend(get_hog_features(feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))      \n",
    "        else:\n",
    "            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "        #8) Append features to list\n",
    "        img_features.append(hog_features)\n",
    "\n",
    "    #9) Return concatenated array of features\n",
    "    return np.concatenate(img_features)\n",
    "\n",
    "# Define a function you will pass an image \n",
    "# and the list of windows to be searched (output of slide_windows())\n",
    "def search_windows(img, windows, clf, scaler):\n",
    "\n",
    "    #1) Create an empty list to receive positive detection windows\n",
    "    on_windows = []\n",
    "    #2) Iterate over all windows in the list\n",
    "    for window in windows:\n",
    "        #3) Extract the test window from original image\n",
    "        test_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))      \n",
    "        #4) Extract features for that window using single_img_features()\n",
    "        features = single_img_features(test_img)\n",
    "        #5) Scale extracted features to be fed to classifier\n",
    "        test_features = scaler.transform(np.array(features).reshape(1, -1))\n",
    "        #6) Predict using your classifier\n",
    "        prediction = clf.predict(test_features)\n",
    "        #7) If positive (prediction == 1) then save the window\n",
    "        if prediction == 1:\n",
    "            on_windows.append(window)\n",
    "    #8) Return windows for positive detections\n",
    "    return on_windows\n",
    "\n",
    "def extract_features(imgs):\n",
    "    features = []\n",
    "    for file in imgs:\n",
    "        file_features = []\n",
    "        image, raw_image = read_image(file)\n",
    "        features.append(single_img_features(image))\n",
    "    return features\n",
    "    \n",
    "# Define a function that takes an image,\n",
    "# start and stop positions in both x and y, \n",
    "# window size (x and y dimensions),  \n",
    "# and overlap fraction (for both x and y)\n",
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            \n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list\n",
    "\n",
    "# Define a function to draw bounding boxes\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy\n",
    "\n",
    "def find_cars(img, draw_img, svc, X_scaler):\n",
    "    \n",
    "    color_space = Configuration().COLOR_SPACE\n",
    "    ystart = Configuration().Y_START_STOP[0]\n",
    "    ystop = Configuration().Y_START_STOP[1]\n",
    "    scale = Configuration().SCALE\n",
    "    orient = Configuration().ORIENTATIONS\n",
    "    pix_per_cell = Configuration().PIX_PER_CELL\n",
    "    cell_per_block = Configuration().CELLS_PER_BLOCK\n",
    "    spatial_size = Configuration().SPATIAL_SIZE\n",
    "    hist_bins = Configuration().HIST_BINS\n",
    "    \n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    ctrans_tosearch = convert_color(img_tosearch, \"RGB\", color_space)\n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "        \n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell)-1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell)-1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell)-1 \n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "    bbox_list = []\n",
    "    \n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            # Extract HOG for this patch\n",
    "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            # Extract the image patch\n",
    "            subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "          \n",
    "            # Get color features\n",
    "            spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "            hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "\n",
    "            # Scale features and make a prediction\n",
    "            test_features = X_scaler.transform(np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))    \n",
    "            #test_features = X_scaler.transform(np.hstack((shape_feat, hist_feat)).reshape(1, -1))    \n",
    "            test_prediction = svc.predict(test_features)\n",
    "            \n",
    "            if test_prediction == 1:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                bbox = ((xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart))\n",
    "                bbox_list.append(bbox)\n",
    "                cv2.rectangle(draw_img, bbox[0], bbox[1] ,(0,0,255),6)\n",
    "                \n",
    "    return draw_img, bbox_list\n",
    "\n",
    "def train_classifier():\n",
    "    # Read in cars and notcars\n",
    "    cars = glob.glob('data/vehicles/**/*.png')\n",
    "    notcars = glob.glob('data/non-vehicles/**/*.png')\n",
    "\n",
    "    # Reduce the sample size because\n",
    "    # The quiz evaluator times out after 13s of CPU time\n",
    "    #sample_size = 10\n",
    "    #cars = cars[0:sample_size]\n",
    "    #notcars = notcars[0:sample_size]\n",
    "\n",
    "    car_features = extract_features(cars)\n",
    "    notcar_features = extract_features(notcars)\n",
    "\n",
    "    #print(car_features)\n",
    "    #print(notcar_features.shape)\n",
    "\n",
    "    X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "    # Fit a per-column scaler\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    # Apply the scaler to X\n",
    "    scaled_X = X_scaler.transform(X)\n",
    "\n",
    "    # Define the labels vector\n",
    "    y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "    # Split up data into randomized training and test sets\n",
    "    #rand_state = np.random.randint(0, 100)\n",
    "    rand_state = 0\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "    print('Feature vector length:', len(X_train[0]))\n",
    "    # Use a linear SVC \n",
    "    svc = LinearSVC()\n",
    "    # Check the training time for the SVC\n",
    "    t=time.time()\n",
    "    svc.fit(X_train, y_train)\n",
    "    t2 = time.time()\n",
    "    print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "    # Check the score of the SVC\n",
    "    print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "    # Check the prediction time for a single sample\n",
    "    t=time.time()\n",
    "    \n",
    "    return svc, X_scaler\n",
    "\n",
    "def test_detection(image, raw_image, svc, X_scaler):\n",
    "    y_start_stop = Configuration().Y_START_STOP\n",
    "    windows = slide_window(image, x_start_stop=[None, None], \n",
    "                           y_start_stop=y_start_stop, xy_window=(96, 96), xy_overlap=(0.5, 0.5))\n",
    "    hot_windows = search_windows(image, windows, svc, X_scaler)\n",
    "    window_img = draw_boxes(raw_image, hot_windows, color=(0, 0, 255), thick=6)                    \n",
    "\n",
    "    return window_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Toolkit for Car Detection Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector length: 6108\n",
      "32.32 Seconds to train SVC...\n",
      "Test Accuracy of SVC =  0.9918\n",
      "image canvas with 2 cols and 3 rows\n",
      "test_images/test1.jpg goes to 0 0\n",
      "test_images/test2.jpg goes to 0 1\n",
      "test_images/test3.jpg goes to 1 0\n",
      "test_images/test4.jpg goes to 1 1\n",
      "test_images/test5.jpg goes to 2 0\n",
      "test_images/test6.jpg goes to 2 1\n"
     ]
    }
   ],
   "source": [
    "svc, X_scaler = train_classifier()\n",
    "\n",
    "image_folder = \"test_images\"\n",
    "image_files = [\"test1.jpg\", \"test2.jpg\", \"test3.jpg\", \"test4.jpg\", \"test5.jpg\", \"test6.jpg\",]\n",
    "image_displays = []\n",
    "\n",
    "for image_file in image_files:\n",
    "    image_file_path = image_folder + \"/\" + image_file\n",
    "    image, raw_image = read_image(image_file_path)\n",
    "    window_img = test_detection(image, raw_image, svc, X_scaler)\n",
    "    image_displays.append(ImageDisplay(window_img, image_file_path, 'hot'))\n",
    "\n",
    "show_multiple(image_displays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image, raw_image = read_image('test_images/test7.jpg')\n",
    "\n",
    "RuntimeData().reset()\n",
    "RuntimeData().heatmap = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "\n",
    "\n",
    "draw_img, bbox_list = find_cars(image, raw_image, svc, X_scaler)\n",
    "\n",
    "RuntimeData().heatmap = add_heat(RuntimeData().heatmap, bbox_list)\n",
    "RuntimeData().heatmap = apply_threshold(RuntimeData().heatmap, 1)\n",
    "heatmap_img = visualize_heatmap(RuntimeData().heatmap)\n",
    "labels = label(RuntimeData().heatmap)\n",
    "out_img = np.dstack((heatmap_img, heatmap_img, heatmap_img))\n",
    "\n",
    "\n",
    "# TODO geht no net\n",
    "draw_img = draw_labeled_bboxes(draw_img, labels)\n",
    "\n",
    "plt.imshow(draw_img)\n",
    "\n",
    "#plt.imshow(labels[0], cmap='gray')\n",
    "#plt.imshow(heatmap_img, cmap='gray')\n",
    "\n",
    "\n",
    "print(np.min(heatmap_img))\n",
    "print(np.max(heatmap_img))\n",
    "\n",
    "# Problem: Bild geht von 0.0 bis 6.0, cv wei net was es anfangen soll\n",
    "\n",
    "cv2.imshow(\"img\", draw_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_image_vehicle_detection(image):\n",
    "    orig_img = np.copy(image)\n",
    "    \n",
    "    raw_image = np.copy(image)\n",
    "    image = image.astype(np.float32)/255\n",
    "    \n",
    "    bbox_img = np.copy(raw_image)\n",
    "    \n",
    "    if RuntimeData().heatmap is None:\n",
    "        RuntimeData().heatmap = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "    \n",
    "    draw_img, bbox_list = find_cars(image, raw_image, svc, X_scaler)\n",
    "    \n",
    "    RuntimeData().heatmap = add_heat(RuntimeData().heatmap, bbox_list, 4)\n",
    "    RuntimeData().heatmap = cooldown(RuntimeData().heatmap, 0)\n",
    "    \n",
    "    heatmap_img = apply_threshold(RuntimeData().heatmap, 10)\n",
    "    heatmap_img = clip_heatmap(RuntimeData().heatmap, 0, 30)\n",
    "    labels = label(heatmap_img)\n",
    "    \n",
    "    \n",
    "    \n",
    "    out_img = np.dstack((heatmap_img, np.zeros_like(heatmap_img), np.zeros_like(heatmap_img)))\n",
    "    \n",
    "    draw_img = draw_labeled_bboxes(bbox_img, labels)\n",
    "    #result = cv2.addWeighted(draw_img.astype(np.float), 1, out_img.astype(np.float), 0.8, 0)\n",
    "    \n",
    "    #cv2.imshow(\"img\", draw_img)\n",
    "    #return draw_img\n",
    "    return concatenate_4_images(raw_image, draw_img, bbox_img, out_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Calibrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Calibrate\n",
    "ret, mtx, dist, rvecs, tvecs = calibrate(9, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Pipeline used for videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video_debug_out.mp4\n",
      "[MoviePy] Writing video project_video_debug_out.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 1236/1261 [14:36<00:16,  1.54it/s]"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "left_line = Line()\n",
    "right_line = Line()\n",
    "RuntimeData().reset()\n",
    "\n",
    "#video = \"test_video\"\n",
    "video = \"project_video\"\n",
    "#video = \"challenge_video\"\n",
    "#video = \"harder_challenge_video\"\n",
    "\n",
    "mode = \"debug\"\n",
    "#mode = \"with_pipeline_1\"\n",
    "\n",
    "white_output = video + \"_\" + mode + \"_out.mp4\"\n",
    "clip1 = VideoFileClip(video + \".mp4\")\n",
    "\n",
    "# choose pipeline\n",
    "#white_clip = clip1.fl_image(process_image_video1)\n",
    "white_clip = clip1.fl_image(process_image_vehicle_detection)\n",
    "#white_clip = clip1.fl_image(process_image)\n",
    "#white_clip = clip1.fl_image(process_image_find_cspace)\n",
    "\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
